{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f45171fb",
   "metadata": {},
   "source": [
    "# Predictive Modeling Database Creation Notebook\n",
    "\n",
    "## Description:\n",
    "\n",
    "This notebook serves as a guide for creating databases tailored specifically for predictive modeling tasks. The primary objective is to design and build databases that support machine learning models by providing well-structured data and meaningful features.\n",
    "\n",
    "In this notebook, we'll cover the process of database creation with a focus on enhancing data quality and feature engineering. \n",
    "\n",
    "Additionally, we'll explore methods for generating and incorporating features into the database to enhance the predictive power of machine learning models. These features may include engineered attributes, transformed variables, or aggregated statistics derived from the raw data.\n",
    "\n",
    "\n",
    "**Author:** [Caique Matos]\n",
    "**Date:** [04/16/24]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9efdb349",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy as cp\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "from pandas_profiling import ProfileReport\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import math\n",
    "import spacy\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.probability import FreqDist\n",
    "from wordcloud import WordCloud\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.stem import PorterStemmer\n",
    "from wordcloud import WordCloud\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "\n",
    "from sklearn.metrics import jaccard_score\n",
    "import itertools\n",
    "\n",
    "import re\n",
    "\n",
    "import scipy.stats as ss\n",
    "from scipy.stats import kruskal\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "import pickle\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.utils import simple_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7c165d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import LdaModel\n",
    "from gensim import corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aeaad883",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5808eca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:/Users/caiqu/OneDrive/Competitions/sony/input/dataset/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e4977de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_excel(path+\"train_set.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef969853",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_excel(path+\"test_set.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6609e893",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'SRC_TITLE_ID', 'SRC_TITLE_NM', 'TITLE_TYPE', 'TITLE_YR',\n",
       "       'RELEASE_DT', 'RUN_TIME', 'PLOT_OUTLINE', 'PLOT_MEDIUM', 'PLOT_SUMMARY',\n",
       "       'RATING_AVG', 'NO_OF_VOTES', 'BUDGET_AMT', 'SRC_GENRE'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd1bd9dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'SRC_TITLE_ID', 'SRC_TITLE_NM', 'TITLE_TYPE', 'TITLE_YR',\n",
       "       'RELEASE_DT', 'RUN_TIME', 'PLOT_OUTLINE', 'PLOT_MEDIUM', 'PLOT_SUMMARY',\n",
       "       'RATING_AVG', 'NO_OF_VOTES', 'BUDGET_AMT'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6bac65b",
   "metadata": {},
   "source": [
    "Este notebook é dedicado em montar a base de dados que sera utilizada pelo modelo preditor de generos.\n",
    "Utilizaremos os conhecimentos descobertos durante o EDA para extrair feature, tratar os dados textuais e demais necessidades de tratamento de dados.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2325901c",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ce1359",
   "metadata": {},
   "source": [
    "### Handle Missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "832eb1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling in missing values ​​with the median\n",
    "df_train['RUN_TIME'].fillna(df_train['RUN_TIME'].median(), inplace=True)\n",
    "df_test['RUN_TIME'].fillna(df_test['RUN_TIME'].median(), inplace=True)\n",
    "\n",
    "#We will use the average per hour, but we may choose to remove due to the large number of missing films\n",
    "df_train['BUDGET_AMT'].fillna(df_train['BUDGET_AMT'].median(), inplace=True)\n",
    "df_test['BUDGET_AMT'].fillna(df_test['BUDGET_AMT'].median(), inplace=True)\n",
    "\n",
    "\n",
    "df_train['PLOT_OUTLINE'].fillna('', inplace=True)\n",
    "df_test['PLOT_OUTLINE'].fillna('', inplace=True)\n",
    "\n",
    "df_train['PLOT_MEDIUM'].fillna('', inplace=True)\n",
    "df_test['PLOT_MEDIUM'].fillna('', inplace=True)\n",
    "\n",
    "df_train['PLOT_SUMMARY'].fillna('', inplace=True)\n",
    "df_test['PLOT_SUMMARY'].fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980f768b",
   "metadata": {},
   "source": [
    "### Temporal Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53ac3a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting 'RELEASE_DT' to date format in df_train\n",
    "df_train['RELEASE_DT'] = pd.to_datetime(df_train['RELEASE_DT'])\n",
    "\n",
    "# Extracting the day and month in df_train\n",
    "df_train['RELEASE_DAY'] = df_train['RELEASE_DT'].dt.day\n",
    "df_train['RELEASE_MONTH'] = df_train['RELEASE_DT'].dt.month\n",
    "\n",
    "\n",
    "df_test['RELEASE_DT'] = pd.to_datetime(df_test['RELEASE_DT'])\n",
    "\n",
    "df_test['RELEASE_DAY'] = df_test['RELEASE_DT'].dt.day\n",
    "df_test['RELEASE_MONTH'] = df_test['RELEASE_DT'].dt.month"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ffb3e9",
   "metadata": {},
   "source": [
    "### Top terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ae41709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the most common terms in a text\n",
    "def calculate_top_terms(text_column, num_top_terms=20):\n",
    "    # Replace NaN values with an empty string\n",
    "    text_column = text_column.fillna('')\n",
    "    \n",
    "    # Text preprocessing (removing stopwords, punctuation, etc.) and tokenization\n",
    "    vectorizer = CountVectorizer(stop_words='english')\n",
    "    X = vectorizer.fit_transform(text_column.astype(str))  # Converting to string\n",
    "    \n",
    "    # Calculate word frequencies\n",
    "    word_frequencies = X.sum(axis=0)\n",
    "\n",
    "    # Get the most common terms\n",
    "    terms = vectorizer.get_feature_names_out()\n",
    "    word_freq_df = pd.DataFrame({'Term': terms, 'Frequency': word_frequencies.flat})\n",
    "    word_freq_df = word_freq_df.sort_values(by='Frequency', ascending=False)\n",
    "    \n",
    "    # Return the most common terms\n",
    "    return word_freq_df['Term'][:num_top_terms].tolist()\n",
    "\n",
    "# Function to add columns of most common terms to a DataFrame\n",
    "def add_top_terms_columns(df, text_columns, num_top_terms=20):\n",
    "    for column in text_columns:\n",
    "        # Calculate the most common terms for the column\n",
    "        top_terms = calculate_top_terms(df[column], num_top_terms)\n",
    "        \n",
    "        # Add the most common terms as a new column in the DataFrame\n",
    "        df[f'TOP_TERMS_{column}'] = df[column].apply(lambda text: [term for term in top_terms if isinstance(text, str) and term in text.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e72b8a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of text columns to process\n",
    "text_columns = ['PLOT_SUMMARY', 'PLOT_OUTLINE', 'PLOT_MEDIUM', 'SRC_TITLE_NM']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d41736",
   "metadata": {},
   "source": [
    "### Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be4620d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment(df, column_name):\n",
    "    # Initialize the sentiment analyzer\n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "    # Function to assign a sentiment label based on the sentiment compound score\n",
    "    def sentiment_label(score):\n",
    "        if score >= 0.05:\n",
    "            return 'Positive'\n",
    "        elif score <= -0.05:\n",
    "            return 'Negative'\n",
    "        else:\n",
    "            return 'Neutral'\n",
    "\n",
    "    # Calculate sentiment for each entry in the specified column\n",
    "    sentiments = []\n",
    "    for text in df[column_name]:\n",
    "        # Calculate sentiment score\n",
    "        sentiment_score = sia.polarity_scores(str(text))['compound']\n",
    "        # Assign a sentiment label\n",
    "        label = sentiment_label(sentiment_score)\n",
    "        sentiments.append(label)\n",
    "\n",
    "    # Add sentiment labels to the DataFrame\n",
    "    df[column_name + '_SENTIMENT'] = sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad9f36e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_sentiment(df_train, 'PLOT_OUTLINE')\n",
    "analyze_sentiment(df_test, 'PLOT_OUTLINE')\n",
    "\n",
    "analyze_sentiment(df_train, 'PLOT_MEDIUM')\n",
    "analyze_sentiment(df_test, 'PLOT_MEDIUM')\n",
    "\n",
    "analyze_sentiment(df_train, 'PLOT_SUMMARY')\n",
    "analyze_sentiment(df_test, 'PLOT_SUMMARY')\n",
    "\n",
    "analyze_sentiment(df_train, 'SRC_TITLE_NM')\n",
    "analyze_sentiment(df_test, 'SRC_TITLE_NM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63ed249b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_categorical_columns(df, categorical_columns, encoder_filename):\n",
    "    \n",
    "    encoder = OrdinalEncoder()\n",
    "    encoder.fit(df[categorical_columns])\n",
    "    encoded_data = encoder.transform(df[categorical_columns])\n",
    "    \n",
    "    \n",
    "    # Save the encoder model\n",
    "#     with open(encoder_filename, 'wb') as file:\n",
    "#         pickle.dump(encoder, file)\n",
    "    \n",
    "    for i, column in enumerate(categorical_columns):\n",
    "        new_column_name = f\"{column}_ENCODED\"\n",
    "        df[new_column_name] = encoded_data[:, i]+1\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f49a2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mapping categorical to number\n",
    "\n",
    "categorical_columns = ['PLOT_SUMMARY_SENTIMENT','SRC_TITLE_NM_SENTIMENT','PLOT_OUTLINE_SENTIMENT','PLOT_MEDIUM_SENTIMENT']\n",
    "\n",
    "df_train = encode_categorical_columns(df_train, categorical_columns, 'encoder_fulltrain.pkl')\n",
    "df_test = encode_categorical_columns(df_test, categorical_columns, 'encoder_fulltest.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70f7c66",
   "metadata": {},
   "source": [
    "### Entities and Dominant Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6aa2c619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the dominant topic of a text\n",
    "def get_dominant_topic(lda_model, text):\n",
    "    # Converting the text into a bag-of-words format\n",
    "    bow = dictionary.doc2bow(text.split())\n",
    "\n",
    "    # Getting the topic distribution for the document\n",
    "    topic_distribution = lda_model.get_document_topics(bow)\n",
    "\n",
    "    # Returning the topic with the highest score\n",
    "    dominant_topic = max(topic_distribution, key=lambda x: x[1])[0]\n",
    "\n",
    "    return dominant_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6e7237fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over the text columns\n",
    "for column in text_columns:\n",
    "    # Convert the values in the column to string\n",
    "    texts = df_train[column].astype(str).tolist()\n",
    "    tokens = [text.split() for text in texts]\n",
    "    dictionary = Dictionary(tokens)\n",
    "\n",
    "    # Filter extreme tokens in the dictionary (optional)\n",
    "    dictionary.filter_extremes(no_below=5, no_above=0.5)\n",
    "\n",
    "    # Create a corpus from the texts\n",
    "    corpus = [dictionary.doc2bow(tokens) for tokens in tokens]\n",
    "\n",
    "    # Train the LDA model\n",
    "    lda_model = LdaModel(corpus=corpus, id2word=dictionary, num_topics=10, passes=10)\n",
    "\n",
    "    # Adding a new column 'DOMINANT_TOPIC' to the DataFrame\n",
    "    df_train[column + '_DOMINANT_TOPIC'] = [get_dominant_topic(lda_model, text) for text in texts]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "444c0aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over the text columns\n",
    "for column in text_columns:\n",
    "    # Convert the values in the column to string\n",
    "    texts = df_test[column].astype(str).tolist()\n",
    "    tokens = [text.split() for text in texts]\n",
    "    dictionary = Dictionary(tokens)\n",
    "\n",
    "    # Filter extreme tokens in the dictionary (optional)\n",
    "    dictionary.filter_extremes(no_below=5, no_above=0.5)\n",
    "\n",
    "    # Create a corpus from the texts\n",
    "    corpus = [dictionary.doc2bow(tokens) for tokens in tokens]\n",
    "\n",
    "    # Train the LDA model\n",
    "    lda_model = LdaModel(corpus=corpus, id2word=dictionary, num_topics=10, passes=10)\n",
    "\n",
    "    # Adding a new column 'DOMINANT_TOPIC' to the DataFrame\n",
    "    df_test[column + '_DOMINANT_TOPIC'] = [get_dominant_topic(lda_model, text) for text in texts]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0022b465",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "df_train['RATING_AVG'] = scaler.fit_transform(df_train[['RATING_AVG']])\n",
    "df_test['RATING_AVG'] = scaler.fit_transform(df_test[['RATING_AVG']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f17eb1e",
   "metadata": {},
   "source": [
    "### Vectorizing Text Columns\n",
    "\n",
    "This step should be at The models notebooks due to specificity of each models embedding.\n",
    "\n",
    "\n",
    "### Umbalance Class in Genres\n",
    "\n",
    "Class imbalance in movie genres occurs when some genres have significantly fewer instances compared to others. This can lead to biased models that perform poorly in predicting underrepresented genres.\n",
    "\n",
    "To address this issue, under sampling reduces the number of instances in the majority class, while oversampling increases the instances in the minority class. Both techniques aim to balance the class distribution and improve model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca92df1",
   "metadata": {},
   "source": [
    "### Under Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a6fb624c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obter os 12 gêneros com mais amostras\n",
    "top_genres = df_train['SRC_GENRE'].value_counts().nlargest(7).index\n",
    "\n",
    "# Filtrar o DataFrame original para incluir apenas os filmes desses gêneros\n",
    "df_under = df_train[df_train['SRC_GENRE'].isin(top_genres)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f5ea3f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = ['SRC_GENRE']\n",
    "df_under = encode_categorical_columns(df_under, categorical_columns, 'encoder_2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0b1913bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Drama          3131\n",
       "Documentary    2829\n",
       "Comedy         2277\n",
       "Action         1120\n",
       "Horror          696\n",
       "Crime           440\n",
       "Adventure       284\n",
       "Name: SRC_GENRE, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_under['SRC_GENRE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dbd1eadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_validation, df_under = train_test_split(df_under, test_size=0.95, random_state=12)\n",
    "df_validation.to_csv(path+ '../df_validation_under.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ec4d541b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_csv(path+ '../df_test.csv', index=False)\n",
    "df_under.to_csv(path+ '../df_train_under.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f2e9fa9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>SRC_TITLE_ID</th>\n",
       "      <th>SRC_TITLE_NM</th>\n",
       "      <th>TITLE_TYPE</th>\n",
       "      <th>TITLE_YR</th>\n",
       "      <th>RELEASE_DT</th>\n",
       "      <th>RUN_TIME</th>\n",
       "      <th>PLOT_OUTLINE</th>\n",
       "      <th>PLOT_MEDIUM</th>\n",
       "      <th>PLOT_SUMMARY</th>\n",
       "      <th>RATING_AVG</th>\n",
       "      <th>NO_OF_VOTES</th>\n",
       "      <th>BUDGET_AMT</th>\n",
       "      <th>SRC_GENRE</th>\n",
       "      <th>RELEASE_DAY</th>\n",
       "      <th>RELEASE_MONTH</th>\n",
       "      <th>PLOT_OUTLINE_SENTIMENT</th>\n",
       "      <th>PLOT_MEDIUM_SENTIMENT</th>\n",
       "      <th>PLOT_SUMMARY_SENTIMENT</th>\n",
       "      <th>SRC_TITLE_NM_SENTIMENT</th>\n",
       "      <th>PLOT_SUMMARY_SENTIMENT_ENCODED</th>\n",
       "      <th>SRC_TITLE_NM_SENTIMENT_ENCODED</th>\n",
       "      <th>PLOT_OUTLINE_SENTIMENT_ENCODED</th>\n",
       "      <th>PLOT_MEDIUM_SENTIMENT_ENCODED</th>\n",
       "      <th>PLOT_SUMMARY_DOMINANT_TOPIC</th>\n",
       "      <th>PLOT_OUTLINE_DOMINANT_TOPIC</th>\n",
       "      <th>PLOT_MEDIUM_DOMINANT_TOPIC</th>\n",
       "      <th>SRC_TITLE_NM_DOMINANT_TOPIC</th>\n",
       "      <th>SRC_GENRE_ENCODED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11004</th>\n",
       "      <td>11005</td>\n",
       "      <td>tt9618458</td>\n",
       "      <td>Night Blooms</td>\n",
       "      <td>movie</td>\n",
       "      <td>2022</td>\n",
       "      <td>2021-09-18</td>\n",
       "      <td>98.00</td>\n",
       "      <td>Jessica Clement stars with Nick Stahl in a 90'...</td>\n",
       "      <td>17 year old Carly initiates a romantic relatio...</td>\n",
       "      <td>Jessica Clement stars with Nick Stahl in a 90'...</td>\n",
       "      <td>0.52</td>\n",
       "      <td>157</td>\n",
       "      <td>300000.00</td>\n",
       "      <td>Drama</td>\n",
       "      <td>18.00</td>\n",
       "      <td>9.00</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>6.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10716</th>\n",
       "      <td>10717</td>\n",
       "      <td>tt2411112</td>\n",
       "      <td>Longwave</td>\n",
       "      <td>movie</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013-07-19</td>\n",
       "      <td>85.00</td>\n",
       "      <td></td>\n",
       "      <td>April 1974. The Federal Councellor, annoyed by...</td>\n",
       "      <td>April 1974. The Federal Councellor, annoyed by...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>623</td>\n",
       "      <td>300000.00</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>19.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7217</th>\n",
       "      <td>7218</td>\n",
       "      <td>tt7197162</td>\n",
       "      <td>Old Man Jackson</td>\n",
       "      <td>movie</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023-06-01</td>\n",
       "      <td>92.00</td>\n",
       "      <td>Mr. Jackson, an award winning automotive mecha...</td>\n",
       "      <td></td>\n",
       "      <td>Mr. Jackson, an award winning automotive mecha...</td>\n",
       "      <td>0.88</td>\n",
       "      <td>70</td>\n",
       "      <td>2500000.00</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>1.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3367</th>\n",
       "      <td>3368</td>\n",
       "      <td>tt1283884</td>\n",
       "      <td>Blodigt jÃ¤vla helvete</td>\n",
       "      <td>movie</td>\n",
       "      <td>2008</td>\n",
       "      <td>2008-02-15</td>\n",
       "      <td>108.00</td>\n",
       "      <td>A rookie cop arrives to the city of Gotland to...</td>\n",
       "      <td></td>\n",
       "      <td>A rookie cop arrives to the city of Gotland to...</td>\n",
       "      <td>0.67</td>\n",
       "      <td>41</td>\n",
       "      <td>300000.00</td>\n",
       "      <td>Action</td>\n",
       "      <td>15.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8557</th>\n",
       "      <td>8558</td>\n",
       "      <td>tt1384925</td>\n",
       "      <td>Ardor</td>\n",
       "      <td>movie</td>\n",
       "      <td>2014</td>\n",
       "      <td>2014-05-12</td>\n",
       "      <td>101.00</td>\n",
       "      <td>A mysterious man emerges from the Argentinean ...</td>\n",
       "      <td>Bordering the vast Amazonian rainforest along ...</td>\n",
       "      <td>A mysterious man emerges from the Argentinean ...</td>\n",
       "      <td>0.52</td>\n",
       "      <td>907</td>\n",
       "      <td>300000.00</td>\n",
       "      <td>Drama</td>\n",
       "      <td>12.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>6.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID SRC_TITLE_ID            SRC_TITLE_NM TITLE_TYPE  TITLE_YR  \\\n",
       "11004  11005    tt9618458            Night Blooms      movie      2022   \n",
       "10716  10717    tt2411112                Longwave      movie      2013   \n",
       "7217    7218    tt7197162         Old Man Jackson      movie      2023   \n",
       "3367    3368    tt1283884  Blodigt jÃ¤vla helvete      movie      2008   \n",
       "8557    8558    tt1384925                   Ardor      movie      2014   \n",
       "\n",
       "      RELEASE_DT  RUN_TIME                                       PLOT_OUTLINE  \\\n",
       "11004 2021-09-18     98.00  Jessica Clement stars with Nick Stahl in a 90'...   \n",
       "10716 2013-07-19     85.00                                                      \n",
       "7217  2023-06-01     92.00  Mr. Jackson, an award winning automotive mecha...   \n",
       "3367  2008-02-15    108.00  A rookie cop arrives to the city of Gotland to...   \n",
       "8557  2014-05-12    101.00  A mysterious man emerges from the Argentinean ...   \n",
       "\n",
       "                                             PLOT_MEDIUM  \\\n",
       "11004  17 year old Carly initiates a romantic relatio...   \n",
       "10716  April 1974. The Federal Councellor, annoyed by...   \n",
       "7217                                                       \n",
       "3367                                                       \n",
       "8557   Bordering the vast Amazonian rainforest along ...   \n",
       "\n",
       "                                            PLOT_SUMMARY  RATING_AVG  \\\n",
       "11004  Jessica Clement stars with Nick Stahl in a 90'...        0.52   \n",
       "10716  April 1974. The Federal Councellor, annoyed by...        0.64   \n",
       "7217   Mr. Jackson, an award winning automotive mecha...        0.88   \n",
       "3367   A rookie cop arrives to the city of Gotland to...        0.67   \n",
       "8557   A mysterious man emerges from the Argentinean ...        0.52   \n",
       "\n",
       "       NO_OF_VOTES  BUDGET_AMT SRC_GENRE  RELEASE_DAY  RELEASE_MONTH  \\\n",
       "11004          157   300000.00     Drama        18.00           9.00   \n",
       "10716          623   300000.00    Comedy        19.00           7.00   \n",
       "7217            70  2500000.00    Comedy         1.00           6.00   \n",
       "3367            41   300000.00    Action        15.00           2.00   \n",
       "8557           907   300000.00     Drama        12.00           5.00   \n",
       "\n",
       "      PLOT_OUTLINE_SENTIMENT PLOT_MEDIUM_SENTIMENT PLOT_SUMMARY_SENTIMENT  \\\n",
       "11004               Positive              Positive               Positive   \n",
       "10716                Neutral              Negative               Negative   \n",
       "7217                Positive               Neutral               Positive   \n",
       "3367                Negative               Neutral               Negative   \n",
       "8557                Negative              Positive               Negative   \n",
       "\n",
       "      SRC_TITLE_NM_SENTIMENT  PLOT_SUMMARY_SENTIMENT_ENCODED  \\\n",
       "11004                Neutral                            3.00   \n",
       "10716                Neutral                            1.00   \n",
       "7217                 Neutral                            3.00   \n",
       "3367                 Neutral                            1.00   \n",
       "8557                 Neutral                            1.00   \n",
       "\n",
       "       SRC_TITLE_NM_SENTIMENT_ENCODED  PLOT_OUTLINE_SENTIMENT_ENCODED  \\\n",
       "11004                            2.00                            3.00   \n",
       "10716                            2.00                            2.00   \n",
       "7217                             2.00                            3.00   \n",
       "3367                             2.00                            1.00   \n",
       "8557                             2.00                            1.00   \n",
       "\n",
       "       PLOT_MEDIUM_SENTIMENT_ENCODED  PLOT_SUMMARY_DOMINANT_TOPIC  \\\n",
       "11004                           3.00                            6   \n",
       "10716                           1.00                            7   \n",
       "7217                            2.00                            7   \n",
       "3367                            2.00                            2   \n",
       "8557                            3.00                            2   \n",
       "\n",
       "       PLOT_OUTLINE_DOMINANT_TOPIC  PLOT_MEDIUM_DOMINANT_TOPIC  \\\n",
       "11004                            8                           9   \n",
       "10716                            0                           7   \n",
       "7217                             7                           0   \n",
       "3367                             2                           0   \n",
       "8557                             2                           9   \n",
       "\n",
       "       SRC_TITLE_NM_DOMINANT_TOPIC  SRC_GENRE_ENCODED  \n",
       "11004                            6               6.00  \n",
       "10716                            0               3.00  \n",
       "7217                             1               3.00  \n",
       "3367                             0               1.00  \n",
       "8557                             0               6.00  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_under.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54cd57d4",
   "metadata": {},
   "source": [
    "### Over Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7393e938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class Balancing\n",
    "\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Determine the minimum number of observations for each genre\n",
    "min_obs_per_genre = 1000\n",
    "\n",
    "# Count the number of observations for each genre\n",
    "genre_counts = df_train['SRC_GENRE'].value_counts()\n",
    "\n",
    "# List the genres with few observations\n",
    "genres_to_oversample = genre_counts[genre_counts < min_obs_per_genre].index.tolist()\n",
    "\n",
    "# Create artificial rows for each genre with few observations\n",
    "for genre in genres_to_oversample:\n",
    "    # Filter the observations for the specific genre\n",
    "    df_genre = df_train[df_train['SRC_GENRE'] == genre]\n",
    "    \n",
    "    # Determine how many artificial observations are needed to equal the minimum number\n",
    "    num_samples_needed = min_obs_per_genre - len(df_genre)\n",
    "    \n",
    "    # Perform oversampling to create artificial rows\n",
    "    df_genre_oversampled = resample(df_genre, \n",
    "                                     replace=True,\n",
    "                                     n_samples=num_samples_needed,\n",
    "                                     random_state=42)\n",
    "    \n",
    "    # Add the artificial rows to the original DataFrame\n",
    "    df_train = pd.concat([df_train, df_genre_oversampled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "13bf9c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = ['SRC_GENRE']\n",
    "df_train = encode_categorical_columns(df_train, categorical_columns,'encoder_3.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6f7400eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_validation, df_train = train_test_split(df_train, test_size=0.95, random_state=42)\n",
    "\n",
    "df_train.to_csv(path+ '../df_train_over.csv', index=False)\n",
    "df_validation.to_csv(path+ '../df_validation_over.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
