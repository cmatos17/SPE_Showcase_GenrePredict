{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1459395b",
   "metadata": {},
   "source": [
    "# LSTM Model for Movie Genre Prediction\n",
    "\n",
    "## Description:\n",
    "\n",
    "This notebook demonstrates the implementation of a Long Short-Term Memory (LSTM) neural network model for predicting movie genres. The primary goal is to develop a deep learning architecture capable of accurately classifying movie genres based on textual data such as movie titles, plot summaries, and sentiment analysis.\n",
    "\n",
    "In this notebook, we'll begin by preprocessing the textual data, which involves tokenization, lemmatization, and encoding of movie genres. We'll then split the dataset into training and testing sets to train and evaluate the LSTM model. The model architecture consists of two LSTM layers followed by a dense output layer with sigmoid activation to predict multiple genres simultaneously.\n",
    "\n",
    "Furthermore, we'll incorporate additional features such as sentiment analysis scores and dominant topics extracted from the text to enhance the predictive performance of the model. The training process involves optimizing the model's parameters using the binary cross-entropy loss function and the Adam optimizer.\n",
    "\n",
    "\n",
    "**Author:** [Caique Matos]\n",
    "**Date:** [04/16/24]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662e27cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "from tensorflow.keras.layers import Input, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d372e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd56b737",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:/Users/caiqu/OneDrive/Competitions/sony/input/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f55396d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(path+'df_train_under.csv')\n",
    "df_valid = pd.read_csv(path+\"df_validation_under.csv\")\n",
    "df_test = pd.read_csv(path+'df_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f370b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a54fb9",
   "metadata": {},
   "source": [
    "## Pre-process and Extracting Value from text columns\n",
    "\n",
    "\n",
    "A abordagem escolhida foi agrupar todas as colunas de texto(título e colunas de resumo de enredo), passando por uma tokenização e por uma fase de \"lematização\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afb9ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pré-processamento do texto\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    if isinstance(text, str):\n",
    "        tokens = nltk.word_tokenize(text.lower())\n",
    "        filtered_tokens = [lemmatizer.lemmatize(token) for token in tokens if token not in stop_words and token.isalnum()]\n",
    "        return ' '.join(filtered_tokens)\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "df_train['processed_title'] = df_train['SRC_TITLE_NM'].fillna('').apply(preprocess_text)\n",
    "df_train['processed_plot'] = df_train['PLOT_SUMMARY'].fillna('').apply(preprocess_text)\n",
    "df_train['processed_plot_outline'] = df_train['PLOT_OUTLINE'].fillna('').apply(preprocess_text)\n",
    "df_train['processed_plot_medium'] = df_train['PLOT_MEDIUM'].fillna('').apply(preprocess_text)\n",
    "df_train['combined_text'] = df_train['processed_title'] + ' ' + df_train['processed_plot'] + df_train['processed_plot_outline']+df_train['processed_plot_medium'] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86771969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pré-processamento dos gêneros\n",
    "df_train['SRC_GENRE'] = df_train['SRC_GENRE'].apply(lambda x: x.split('|'))\n",
    "mlb = MultiLabelBinarizer()\n",
    "genres_encoded = mlb.fit_transform(df_train['SRC_GENRE'])\n",
    "\n",
    "# Carregar os embeddings GloVe pré-treinados\n",
    "embeddings_index = {}\n",
    "with open('glove.6B.100d.txt', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d705213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizar e preencher as sequências de texto\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(df_train['combined_text'])\n",
    "sequences = tokenizer.texts_to_sequences(df_train['combined_text'])\n",
    "word_index = tokenizer.word_index\n",
    "padded_sequences = pad_sequences(sequences, maxlen=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221f21b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar a matriz de embedding\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, 100))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12cf834",
   "metadata": {},
   "source": [
    "## LSTM Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea8618e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define inputs\n",
    "input_text = Input(shape=(300,))\n",
    "input_sentiment = Input(shape=(9,))\n",
    "\n",
    "# Word embedding layer\n",
    "embedding_text = Embedding(len(word_index) + 1, 100, weights=[embedding_matrix], input_length=300, trainable=False)(input_text)\n",
    "\n",
    "# LSTM layer\n",
    "lstm_text = LSTM(128, dropout=0.2, recurrent_dropout=0.2)(embedding_text)\n",
    "\n",
    "# Concatenate LSTM output with sentiment input\n",
    "concatenated = Concatenate()([lstm_text, input_sentiment])\n",
    "\n",
    "# Output layer\n",
    "output = Dense(len(mlb.classes_), activation='sigmoid')(concatenated)\n",
    "\n",
    "# Define model\n",
    "model = Model(inputs=[input_text, input_sentiment], outputs=output)\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train_text, X_test_text, y_train, y_test = train_test_split(padded_sequences, genres_encoded, test_size=0.2, random_state=42)\n",
    "X_train_sentiment, X_test_sentiment, _, _ = train_test_split(df_train[['PLOT_SUMMARY_SENTIMENT_ENCODED', 'SRC_TITLE_NM_SENTIMENT_ENCODED',\n",
    "       'PLOT_OUTLINE_SENTIMENT_ENCODED', 'PLOT_MEDIUM_SENTIMENT_ENCODED',\n",
    "       'PLOT_SUMMARY_DOMINANT_TOPIC', 'PLOT_OUTLINE_DOMINANT_TOPIC',\n",
    "       'PLOT_MEDIUM_DOMINANT_TOPIC', 'SRC_TITLE_NM_DOMINANT_TOPIC','RATING_AVG']], genres_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train model\n",
    "model.fit([X_train_text, X_train_sentiment], y_train, batch_size=64, epochs=20, validation_data=([X_test_text, X_test_sentiment], y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6091e9",
   "metadata": {},
   "source": [
    "### Exploring Training/Validating Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f55ce85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fazer previsões no conjunto de teste\n",
    "y_pred_probs = model.predict([X_test_text, X_test_sentiment])\n",
    "y_pred_classes = np.argmax(y_pred_probs, axis=1)\n",
    "predicted_genres = mlb.classes_[y_pred_classes]\n",
    "\n",
    "# Calcular a acurácia média\n",
    "accuracy = accuracy_score(np.argmax(y_test, axis=1), y_pred_classes)\n",
    "\n",
    "# Calcular a acurácia por gênero\n",
    "genre_accuracy = {}\n",
    "for i, genre in enumerate(mlb.classes_):\n",
    "    genre_accuracy[genre] = accuracy_score(y_test[:, i], y_pred_probs[:, i] > 0.5)\n",
    "\n",
    "# Criar DataFrame com as previsões e os valores reais\n",
    "df_predictions = pd.DataFrame({\n",
    "    'Real_Genre': mlb.inverse_transform(y_test),\n",
    "    'Predicted_Genre': predicted_genres\n",
    "})\n",
    "\n",
    "# Exibir resultados\n",
    "print('Overall Accuracy:', accuracy)\n",
    "print('Genre-wise Accuracy:\\n')\n",
    "for genre, acc in genre_accuracy.items():\n",
    "    print(f'{genre}: {acc}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb7b618",
   "metadata": {},
   "source": [
    "### Outsample Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1c4c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pré-processamento do texto para os dados de validação\n",
    "\n",
    "\n",
    "df_valid['processed_title'] = df_valid['SRC_TITLE_NM'].fillna('').apply(preprocess_text)\n",
    "df_valid['processed_plot'] = df_valid['PLOT_SUMMARY'].fillna('').apply(preprocess_text)\n",
    "df_valid['processed_plot_outline'] = df_valid['PLOT_OUTLINE'].fillna('').apply(preprocess_text)\n",
    "df_valid['processed_plot_medium'] = df_valid['PLOT_MEDIUM'].fillna('').apply(preprocess_text)\n",
    "\n",
    "\n",
    "df_valid['combined_text'] = df_valid['processed_title'] + ' ' + df_valid['processed_plot'] + df_valid['processed_plot_outline']+df_valid['processed_plot_medium'] \n",
    "\n",
    "\n",
    "# Tokenizar e preencher as sequências de texto para os dados de validação\n",
    "sequences_valid = tokenizer.texts_to_sequences(df_valid['combined_text'])\n",
    "padded_sequences_valid = pad_sequences(sequences_valid, maxlen=300)\n",
    "\n",
    "\n",
    "# Pré-processamento dos gêneros no conjunto de validação\n",
    "df_valid['SRC_GENRE'] = df_valid['SRC_GENRE'].apply(lambda x: x.split('|'))\n",
    "genres_encoded_valid = mlb.transform(df_valid['SRC_GENRE'])\n",
    "\n",
    "# Fazer previsões no conjunto de validação\n",
    "y_pred_probs_valid = model.predict([padded_sequences_valid, df_valid[['PLOT_SUMMARY_SENTIMENT_ENCODED', 'SRC_TITLE_NM_SENTIMENT_ENCODED',\n",
    "       'PLOT_OUTLINE_SENTIMENT_ENCODED', 'PLOT_MEDIUM_SENTIMENT_ENCODED',\n",
    "       'PLOT_SUMMARY_DOMINANT_TOPIC', 'PLOT_OUTLINE_DOMINANT_TOPIC',\n",
    "       'PLOT_MEDIUM_DOMINANT_TOPIC', 'SRC_TITLE_NM_DOMINANT_TOPIC','RATING_AVG']]])\n",
    "y_pred_classes_valid = np.argmax(y_pred_probs_valid, axis=1)\n",
    "predicted_genres_valid = mlb.classes_[y_pred_classes_valid]\n",
    "\n",
    "# Adicionar as previsões como uma coluna ao DataFrame df_valid\n",
    "df_valid['Predicted_Genre'] = predicted_genres_valid\n",
    "\n",
    "# Calcular a acurácia média no conjunto de validação\n",
    "accuracy_valid = accuracy_score(np.argmax(genres_encoded_valid, axis=1), y_pred_classes_valid)\n",
    "\n",
    "# Calcular a acurácia por gênero no conjunto de validação\n",
    "genre_accuracy_valid = {}\n",
    "for i, genre in enumerate(mlb.classes_):\n",
    "    genre_accuracy_valid[genre] = accuracy_score(genres_encoded_valid[:, i], y_pred_probs_valid[:, i] > 0.5)\n",
    "\n",
    "# Exibir resultados\n",
    "print('Overall Accuracy (Validation):', accuracy_valid)\n",
    "print('\\n\\nGenre-wise Accuracy (Validation):\\n')\n",
    "for genre, acc in genre_accuracy_valid.items():\n",
    "    print(f'{genre}: {acc}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcef9852",
   "metadata": {},
   "source": [
    "### Predctions for Test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644f8baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['processed_title'] = df_test['SRC_TITLE_NM'].fillna('').apply(preprocess_text)\n",
    "df_test['processed_plot'] = df_test['PLOT_SUMMARY'].fillna('').apply(preprocess_text)\n",
    "df_test['processed_plot_outline'] = df_test['PLOT_OUTLINE'].fillna('').apply(preprocess_text)\n",
    "df_test['processed_plot_medium'] = df_test['PLOT_MEDIUM'].fillna('').apply(preprocess_text)\n",
    "\n",
    "\n",
    "df_test['combined_text'] = df_test['processed_title'] + ' ' + df_test['processed_plot'] + df_test['processed_plot_outline']+df_test['processed_plot_medium'] \n",
    "\n",
    "\n",
    "# Tokenizar e preencher as sequências de texto para os dados de validação\n",
    "sequences_valid = tokenizer.texts_to_sequences(df_test['combined_text'])\n",
    "padded_sequences_valid = pad_sequences(sequences_valid, maxlen=300)\n",
    "\n",
    "\n",
    "# Fazer previsões no conjunto de validação\n",
    "y_pred_probs_valid = model.predict([padded_sequences_valid, df_test[['PLOT_SUMMARY_SENTIMENT_ENCODED', 'SRC_TITLE_NM_SENTIMENT_ENCODED',\n",
    "       'PLOT_OUTLINE_SENTIMENT_ENCODED', 'PLOT_MEDIUM_SENTIMENT_ENCODED',\n",
    "       'PLOT_SUMMARY_DOMINANT_TOPIC', 'PLOT_OUTLINE_DOMINANT_TOPIC',\n",
    "       'PLOT_MEDIUM_DOMINANT_TOPIC', 'SRC_TITLE_NM_DOMINANT_TOPIC','RATING_AVG']]])\n",
    "y_pred_classes_valid = np.argmax(y_pred_probs_valid, axis=1)\n",
    "predicted_genres_valid = mlb.classes_[y_pred_classes_valid]\n",
    "\n",
    "# Adicionar as previsões como uma coluna ao DataFrame df_valid\n",
    "df_test['Predicted_Genre'] = predicted_genres_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625113b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[[ 'ID','SRC_TITLE_ID','Predicted_Genre']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f69995d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['Predicted_Genre'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0bdee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[[ 'ID','Predicted_Genre']].to_csv('output/LSTM_US_test_set_predctions.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
